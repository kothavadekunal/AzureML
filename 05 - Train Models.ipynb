{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models\n",
    "\n",
    "The central goal of machine learning is to train predictive models that can be used by applications. In Azure Machine Learning,  you can use scripts to train models leveraging common machine learning frameworks like Scikit-Learn, Tensorflow, PyTorch, SparkML, and others. You can run these training scripts as experiments in order to track metrics and outputs, which include the trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1649366036303
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.51.0 to work with dia_azureml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training script\n",
    "\n",
    "You're going to use a Python script to train a machine learning model based on the diabates data, so let's start by creating a folder for the script and data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1649366039039
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diabetes-training\\\\diabetes.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'diabetes-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('diabetes.csv', os.path.join(training_folder, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to create the training script and save it in the folder.\n",
    "\n",
    "> **Note**: This code *creates* the script - it doesn't run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes-training/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "# X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "X=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a compute cluster\n",
    "\n",
    "To run a script as an experiment using the ScriptRunConfig, you'll need a compute target.\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to a suitable name for your compute cluster in the code below before running it - you can specify the name of an existing cluster if you have one. Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"dia-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script as an experiment\n",
    "\n",
    "Now you're ready to run the script as an experiment. Note that the default environment does not include the **scikit-learn** package, so you need to explicitly add that to the configuration. The conda environment is built on-demand the first time the experiment is run, and cached for future runs that use the same configuration; so the first run will take a little longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1649366052967
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'mslearn-train-diabetes_1687263351_06cb7dd9',\n",
       " 'target': 'dia-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2023-06-20T12:16:47.174083Z',\n",
       " 'endTimeUtc': '2023-06-20T12:17:04.822505Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n",
       "  'ContentSnapshotId': 'bff60bc4-cc04-4a5d-aa1f-097a7bce8d7c',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'dia-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2023-06-20T12:02:08Z_6cdae01c',\n",
       "   'assetId': 'azureml://locations/eastus/workspaces/fafff4af-d21c-4f90-86f0-99fd4f6bdabe/environments/experiment_env/versions/Autosave_2023-06-20T12:02:08Z_6cdae01c',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'simple_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'azureml-mlflow']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230509.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'user_logs/std_log.txt': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=6J%2BWy6UOWw9d02Z4cHkuIJKiXw4aRoYEkz06lNHom54%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T12%3A03%3A28Z&ske=2023-06-21T20%3A13%3A28Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A09Z&se=2023-06-20T20%3A17%3A09Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=JHlPOuUI9m3P3wOb8889lrJWZhSAkTOKAVo5RfilUTw%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=g4kDfkktj8TQVx9eJR9%2FeQBG06QUrhM%2B5sNWtwsT2Ls%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=kFu%2Fpui9K7PCbqh0lwkAmS0IXefE%2Bser%2F0pk3PKMx2c%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=eb6IGUYQ0XrXvI71D6gFW2Pk5Z%2FB8Nt2CJf9oINqkO4%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=2kvjp08T7LUNXGZSE0%2BqTRuiqMZoaWSl7M6WwbYORRM%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://diaazurestorage9abf7ca80.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1687263351_06cb7dd9/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=rOWE6I5CY2rXxoR9KyxX%2FWJ6dqb6LLMDzsE%2Bc6xu7o8%3D&skoid=1a74dfa9-49eb-4064-8baf-f4fad98d7255&sktid=02903b72-fd5b-493e-9068-04f263f21069&skt=2023-06-20T07%3A00%3A12Z&ske=2023-06-21T15%3A10%3A12Z&sks=b&skv=2019-07-07&st=2023-06-20T12%3A07%3A10Z&se=2023-06-20T20%3A17%3A10Z&sp=r'},\n",
       " 'submittedBy': 'utkarsha sonje'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "# from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                environment=env,\n",
    "                                docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment run\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "# RunDetails(run).show()\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/diabetes_model.pkl\n",
      "system_logs/cs_capability/cs-capability.log\n",
      "system_logs/hosttools_capability/hosttools-capability.log\n",
      "system_logs/lifecycler/execution-wrapper.log\n",
      "system_logs/lifecycler/lifecycler.log\n",
      "system_logs/metrics_capability/metrics-capability.log\n",
      "system_logs/snapshot_capability/snapshot-capability.log\n",
      "user_logs/std_log.txt\n"
     ]
    }
   ],
   "source": [
    "for file in run.get_file_names():\n",
    "    print(file)\n",
    "\n",
    "# Download a named file\n",
    "run.download_file(name='outputs/diabetes_model.pkl', output_file_path='diabetes_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the metrics and outputs from the **Run** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366055677
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the trained model\n",
    "\n",
    "Note that the outputs of the experiment include the trained model file (**diabetes_model.pkl**). You can register this model in your Azure Machine Learning workspace, making it possible to track model versions and retrieve them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366061163
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Script'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: The code above uses *properties* and *tags* to note additional information about the model. The key difference between properties and tags is that properties cannot be changed after the model is registered, while tags for a registered model can be modified.\n",
    "\n",
    "## Create a parameterized training script\n",
    "\n",
    "You can increase the flexibility of your training experiment by adding parameters to your script, enabling you to repeat the same training experiment with different settings. In this case, you'll add a parameter for the regularization rate used by the logistic regression algorithm when training the model.\n",
    "\n",
    "Again, lets start by creating a folder for the parameterized script and the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366064098
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'diabetes-training-params'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/diabetes.csv', os.path.join(training_folder, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a script with an argument for the regularization rate hyperparameter. The argument is read using a Python **argparse.ArgumentParser** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $training_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "# load the diabetes dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script with arguments\n",
    "\n",
    "You run the script as an experiment like you did previously, reusing the environment you created; but this time you must provide the **--reg_rate** parameter that the script expects as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366078595
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                arguments = ['--reg_rate', 0.1],\n",
    "                                environment=env,\n",
    "                                docker_runtime_config=DockerConfiguration(use_docker=True),\n",
    "                                compute_target=cluster_name) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can get the metrics and outputs from the completed run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366082569
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a new version of the model\n",
    "\n",
    "Now that you've trained a new model, you can register it as a new version in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649366090545
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Parameterized script'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy'], 'Regularization Rate': run.get_metrics()['Regularization Rate']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view registered models in your workspace on the **Models** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "If you've finished exploring, you can close this notebook and shut down your compute instance."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python (virenv)",
   "language": "python",
   "name": "virenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
